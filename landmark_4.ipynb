{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Activation , AveragePooling2D , Input ,Dropout\n",
    "from tensorflow.keras.layers import Dense,  MaxPooling2D, Add, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import PReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0809d8721c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 특정 GPU에 1GB 메모리만 할당하도록 제한\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         tf.config.experimental.set_virtual_device_configuration(\n\u001b[1;32m      9\u001b[0m             \u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 특정 GPU에 1GB 메모리만 할당하도록 제한\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0,1], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0,1],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1)])\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 준비 \n",
    "path = '/home/lab07/landmark/'\n",
    "\n",
    "\n",
    "train_path = '/home/lab07/landmark/landmark_image'\n",
    "\n",
    "img_dirs = os.listdir(train_path) # 해당 path안에 폴더 이름 리스트에 담기\n",
    "label_df = pd.read_csv(path + '/category.csv') # 각 랜드마크별 label\n",
    "\n",
    "label_dict = dict(label_df[['landmark_name', 'landmark_id']].values) # 폴더경로 저장용\n",
    "label_dict_reverse = dict(label_df.values) # 시각화용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>수영구청/수영구청_011.JPG</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수영구청/수영구청_008.JPG</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>수영구청/수영구청_060.JPG</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수영구청/수영구청_075.JPG</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>수영구청/수영구청_023.JPG</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                file  label\n",
       "0  수영구청/수영구청_011.JPG    794\n",
       "1  수영구청/수영구청_008.JPG    794\n",
       "2  수영구청/수영구청_060.JPG    794\n",
       "3  수영구청/수영구청_075.JPG    794\n",
       "4  수영구청/수영구청_023.JPG    794"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일(JPG)명과 label 정보를 담은 데이터 프레임 생성\n",
    "train_files = []\n",
    "train_categories=[]\n",
    "for img_dir in img_dirs:\n",
    "    img_dir_list = os.listdir(train_path + '/' + img_dir)\n",
    "    for filename in img_dir_list:\n",
    "        train_files.append(img_dir + '/' + filename)\n",
    "        train_categories.append(label_dict[img_dir])\n",
    "    \n",
    "train_data=pd.DataFrame(\n",
    "                    {\"file\":train_files,\n",
    "                    \"label\":train_categories}\n",
    "                )    \n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_data, test_size=0.2, random_state=42,\n",
    "                stratify=train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70481 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                    vertical_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    train_path,\n",
    "    x_col= \"file\",\n",
    "    y_col= \"label\",\n",
    "    target_size = (400,400),\n",
    "    class_mode = \"raw\",\n",
    "    batch_size = 12\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17621 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    valid_df,\n",
    "    train_path,\n",
    "    x_col= \"file\",\n",
    "    y_col= \"label\",\n",
    "    target_size = (400,400),\n",
    "    class_mode = \"raw\",\n",
    "    batch_size = 12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 2s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 12, 12, 1920)      18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1049)              2015129   \n",
      "=================================================================\n",
      "Total params: 20,337,113\n",
      "Trainable params: 20,108,057\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "Epoch 1/10000\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 604 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 604 all-reduces with algorithm = nccl, num_packs = 1\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 6.7741 - sparse_categorical_accuracy: 0.0287\n",
      "Epoch 00001: val_loss improved from inf to 6.06606, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4296s 731ms/step - loss: 6.7741 - sparse_categorical_accuracy: 0.0287 - val_loss: 6.0661 - val_sparse_categorical_accuracy: 0.1884\n",
      "Epoch 2/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 5.4887 - sparse_categorical_accuracy: 0.3875\n",
      "Epoch 00002: val_loss improved from 6.06606 to 3.59317, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4275s 728ms/step - loss: 5.4887 - sparse_categorical_accuracy: 0.3875 - val_loss: 3.5932 - val_sparse_categorical_accuracy: 0.6917\n",
      "Epoch 3/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 3.6386 - sparse_categorical_accuracy: 0.7168\n",
      "Epoch 00003: val_loss improved from 3.59317 to 1.52256, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4274s 728ms/step - loss: 3.6386 - sparse_categorical_accuracy: 0.7168 - val_loss: 1.5226 - val_sparse_categorical_accuracy: 0.8482\n",
      "Epoch 4/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 1.8510 - sparse_categorical_accuracy: 0.8687\n",
      "Epoch 00004: val_loss improved from 1.52256 to 0.54238, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4276s 728ms/step - loss: 1.8510 - sparse_categorical_accuracy: 0.8687 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.9271\n",
      "Epoch 5/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 0.7791 - sparse_categorical_accuracy: 0.9383\n",
      "Epoch 00005: val_loss improved from 0.54238 to 0.20569, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4276s 728ms/step - loss: 0.7791 - sparse_categorical_accuracy: 0.9383 - val_loss: 0.2057 - val_sparse_categorical_accuracy: 0.9632\n",
      "Epoch 6/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 0.3363 - sparse_categorical_accuracy: 0.9694\n",
      "Epoch 00006: val_loss improved from 0.20569 to 0.12269, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4278s 728ms/step - loss: 0.3363 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.1227 - val_sparse_categorical_accuracy: 0.9745\n",
      "Epoch 7/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 0.1540 - sparse_categorical_accuracy: 0.9858\n",
      "Epoch 00007: val_loss improved from 0.12269 to 0.07945, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4278s 728ms/step - loss: 0.1540 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.0794 - val_sparse_categorical_accuracy: 0.9817\n",
      "Epoch 8/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 0.0819 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 00008: val_loss improved from 0.07945 to 0.05811, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4275s 728ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0581 - val_sparse_categorical_accuracy: 0.9865\n",
      "Epoch 9/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 0.0446 - sparse_categorical_accuracy: 0.9972\n",
      "Epoch 00009: val_loss improved from 0.05811 to 0.05201, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4277s 728ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0520 - val_sparse_categorical_accuracy: 0.9866\n",
      "Epoch 10/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 0.0280 - sparse_categorical_accuracy: 0.9985\n",
      "Epoch 00010: val_loss improved from 0.05201 to 0.04531, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4277s 728ms/step - loss: 0.0280 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0453 - val_sparse_categorical_accuracy: 0.9886\n",
      "Epoch 11/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 0.0182 - sparse_categorical_accuracy: 0.9993\n",
      "Epoch 00011: val_loss did not improve from 0.04531\n",
      "5874/5873 [==============================] - 4273s 728ms/step - loss: 0.0182 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0468 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 12/10000\n",
      "5874/5873 [==============================] - ETA: 0s - loss: 0.0121 - sparse_categorical_accuracy: 0.9996\n",
      "Epoch 00012: val_loss improved from 0.04531 to 0.04210, saving model to ./dense_400_400.h5\n",
      "5874/5873 [==============================] - 4274s 728ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0421 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 13/10000\n",
      " 312/5873 [>.............................] - ETA: 1:03:39 - loss: 0.0080 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c899c8e0c0dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_lr_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                         validation_steps=len(valid_df)/12)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow_addons.optimizers import RectifiedAdam\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "# def scheduler(epoch):\n",
    "#   if epoch < 10:\n",
    "#     return 0.0001\n",
    "#   else:\n",
    "#     return 0.0001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "# with tf.device('/device:GPU:0'):\n",
    "\n",
    "    def get_lr_callback():\n",
    "        lr_start   = 0.000001*10*0.5\n",
    "        lr_max     = 0.0000005 * 12 * 10*0.5\n",
    "        lr_min     = 0.000001 * 10*0.5\n",
    "        lr_ramp_ep = 5\n",
    "        lr_sus_ep  = 0\n",
    "        lr_decay   = 0.8\n",
    "\n",
    "\n",
    "        def lrfn(epoch):\n",
    "            if epoch < lr_ramp_ep:\n",
    "                lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n",
    "            elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "                lr = lr_max    \n",
    "            else:\n",
    "                lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n",
    "            return lr\n",
    "\n",
    "        lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\n",
    "        return lr_callback\n",
    "\n",
    "    # learning = tf.keras.callbacks.LearningRateScheduler(get_lr_callback)\n",
    "\n",
    "\n",
    "\n",
    "    DenseNet201_base = DenseNet201(weights='imagenet',\n",
    "                              include_top=False,\n",
    "                              input_shape=(400,400,3))\n",
    "\n",
    "    DenseNet201_base.trainable = True  # Convolution Layer 동결\n",
    "\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    model.add(DenseNet201_base)\n",
    "\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(1049,\n",
    "                    activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # model.load_weights('./project_model/efficientnetb6.h5')\n",
    "\n",
    "    # Model saving callback\n",
    "    checkpointer = ModelCheckpoint(filepath='./dense_400_400.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True)\n",
    "\n",
    "\n",
    "    # opt = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', verbose=2, patience=5)\n",
    "\n",
    "    model.compile(optimizer=RectifiedAdam(learning_rate=1e-4),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "    history = model.fit(train_generator,\n",
    "                        steps_per_epoch=len(train_df)/12, # batch_size * steps_per_epoch > data의 양 xxxxx\n",
    "                        epochs=10000,\n",
    "                        callbacks=[checkpointer, early_stopping, get_lr_callback()],\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(valid_df)/12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_TF2] *",
   "language": "python",
   "name": "conda-env-data_env_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
